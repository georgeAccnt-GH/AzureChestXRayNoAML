{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (C) Microsoft Corporation.  \n",
    "see license file for details \n",
    "\n",
    "### Builds docker image for training (experimentation)\n",
    "\n",
    "Runs basic tests and pushes image to dockerhub  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow multiple displays per cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv_file_path='./../not_shared/general.env'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/datadrive01/prj/AzureChestXRayNoAML/code\n",
      "total 788\n",
      "-rw-rw-r-- 1 loginvm022 loginvm022   7566 Nov 16 22:44 000_setup_azure_sa.ipynb\n",
      "-rwxrwxr-x 1 loginvm022 loginvm022 473751 Nov 16 22:43 00_create_docker_image.html\n",
      "-rwxrwxr-x 1 loginvm022 loginvm022  37116 Nov 16 22:44 010_create_training_docker_image.ipynb\n",
      "drwxrwxr-x 5 loginvm022 loginvm022   4096 Nov 16 22:12 01_DataPrep\n",
      "drwxrwxr-x 2 loginvm022 loginvm022   4096 Nov 14 11:30 02_Model\n",
      "drwxrwxr-x 2 loginvm022 loginvm022   4096 Nov 14 11:53 docker_history\n",
      "-rwxrwxr-x 1 loginvm022 loginvm022 256521 Nov 16 04:29 edit_python_files.html\n",
      "-rwxrwxr-x 1 loginvm022 loginvm022   7152 Nov 16 04:30 edit_python_files.ipynb\n",
      "drwxrwxr-x 3 loginvm022 loginvm022   4096 Nov 15 04:58 src\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "!ls -l ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'georgedockeraccount'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'/chestxray-no-aml-gpu-root-account'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'1.0.4'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%dotenv $dotenv_file_path\n",
    "\n",
    "# Your docker login and image repository name\n",
    "docker_login = os.getenv('docker_login') \n",
    "image_tag = os.getenv('image_tag')\n",
    "image_version = os.getenv('image_version')\n",
    "\n",
    "docker_login\n",
    "image_tag\n",
    "image_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.4'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%dotenv\n",
    "os.getenv('image_version')\n",
    "dockerfile_name = 'dockerfile'+ '_' + os.getenv('image_version')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./../docker/dockerfile_1.0.4\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./../docker/$dockerfile_name\n",
    "\n",
    "FROM nvidia/cuda:10.0-cudnn7-devel\n",
    "# FROM nvidia/cuda:9.2-cudnn7-devel\n",
    "#FROM nvidia/cuda:9.0-cudnn7-devel-ubuntu16.04\n",
    "\n",
    "MAINTAINER George Iordanescu <ghiordan@microsoft.com>\n",
    "#based on https://github.com/keras-team/keras/blob/master/docker/Dockerfile\n",
    "\n",
    "# Install system packages\n",
    "RUN apt-get update && apt-get install -y --no-install-recommends \\\n",
    "      apt-utils \\\n",
    "      bzip2 \\\n",
    "      g++ \\\n",
    "      git \\\n",
    "      graphviz \\\n",
    "      libgl1-mesa-glx \\\n",
    "      libhdf5-dev \\\n",
    "      openmpi-bin \\\n",
    "      wget \\\n",
    "      ssh \\\n",
    "      rsync && \\\n",
    "    rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "# Install conda\n",
    "ENV CONDA_DIR /opt/conda\n",
    "ENV PATH $CONDA_DIR/bin:$PATH\n",
    "\n",
    "RUN wget --quiet --no-check-certificate https://repo.continuum.io/miniconda/Miniconda3-4.2.12-Linux-x86_64.sh && \\\n",
    "    echo \"c59b3dd3cad550ac7596e0d599b91e75d88826db132e4146030ef471bb434e9a *Miniconda3-4.2.12-Linux-x86_64.sh\" | sha256sum -c - && \\\n",
    "    /bin/bash /Miniconda3-4.2.12-Linux-x86_64.sh -f -b -p $CONDA_DIR && \\\n",
    "    rm Miniconda3-4.2.12-Linux-x86_64.sh && \\\n",
    "    echo export PATH=$CONDA_DIR/bin:'$PATH' > /etc/profile.d/conda.sh        \n",
    "\n",
    "# Install AzCopy        \n",
    "RUN mkdir -p /tmp/azcopy && mkdir -p /azcopy10 && \\\n",
    "    wget -O /tmp/azcopy/azcopyv10.tar.gz https://aka.ms/downloadazcopy-v10-linux &&  \\\n",
    "    tar -xf /tmp/azcopy/azcopyv10.tar.gz -C /azcopy10 \n",
    "RUN rm -rf /tmp/azcopy\n",
    "ENV PATH=/azcopy10/azcopy_linux_amd64_10.3.2:$PATH\n",
    "\n",
    "# Install Python packages and keras\n",
    "# ENV NB_USER keras\n",
    "# ENV NB_UID 1000\n",
    "\n",
    "# RUN useradd -m -s /bin/bash -N -u $NB_UID $NB_USER && \\\n",
    "#     chown $NB_USER $CONDA_DIR -R && \\\n",
    "#     mkdir -p /src && \\\n",
    "#     chown $NB_USER /src\n",
    "\n",
    "# USER $NB_USER\n",
    "RUN mkdir -p /sr\n",
    "\n",
    "ARG python_version=3.6\n",
    "\n",
    "RUN conda config --append channels conda-forge\n",
    "RUN conda install -y python=${python_version} && \\\n",
    "    pip install --upgrade pip && \\\n",
    "    pip install \\\n",
    "      sklearn_pandas \\\n",
    "      tensorflow-gpu==1.14 \\\n",
    "      python-dotenv \\\n",
    "      papermill[azure] &&  \\\n",
    "    conda install \\\n",
    "      bcolz \\\n",
    "      h5py \\\n",
    "      imageio \\\n",
    "      matplotlib \\\n",
    "      mkl \\\n",
    "      numpy \\\n",
    "      nose \\\n",
    "      notebook \\\n",
    "      opencv \\\n",
    "      Pillow \\\n",
    "      pandas \\\n",
    "      pydot \\\n",
    "      pygpu \\\n",
    "      pyyaml \\\n",
    "      scikit-learn \\\n",
    "      scikit-image \\\n",
    "      six \\\n",
    "      theano \\\n",
    "      mkdocs \\\n",
    "      tqdm \\\n",
    "      && \\\n",
    "    conda install pytorch torchvision cudatoolkit=9.2 -c pytorch && \\\n",
    "    git clone git://github.com/keras-team/keras.git /src && pip install -e /src[tests] && \\\n",
    "    pip install git+git://github.com/keras-team/keras.git && \\\n",
    "    pip install git+https://github.com/aleju/imgaug && \\\n",
    "    conda clean -yt\n",
    "\n",
    "# TF 1.13:cuda 10.0, cudnn 7 \n",
    "# RUN conda install -y python=${python_version} && \\\n",
    "#     pip install --upgrade pip && \\\n",
    "#     pip install \\\n",
    "#       sklearn_pandas \\\n",
    "#       scikit-image \\\n",
    "#       tensorflow-gpu==1.14 \\\n",
    "#       tensorflow-tensorboard \\\n",
    "#       matplotlib \\\n",
    "#       numpy && \\\n",
    "#     conda install \\\n",
    "#       bcolz \\\n",
    "#       h5py \\\n",
    "#       matplotlib \\\n",
    "#       mkl \\\n",
    "#       nose \\\n",
    "#       notebook \\\n",
    "#       opencv \\\n",
    "#       Pillow \\\n",
    "#       pandas \\\n",
    "#       pydot \\\n",
    "#       pygpu \\\n",
    "#       pyyaml \\\n",
    "#       requests \\\n",
    "#       scikit-learn \\\n",
    "#       six \\\n",
    "#       tqdm \\\n",
    "#       pytorch torchvision cudatoolkit=9.0 -c pytorch && \\\n",
    "#     conda install -c conda-forge imageio && \\\n",
    "#     git clone git://github.com/keras-team/keras.git /src && pip install -e /src[tests] && \\\n",
    "#     pip install git+git://github.com/keras-team/keras.git && \\\n",
    "#     pip install git+https://github.com/aleju/imgaug && \\\n",
    "#     pip install git+https://www.github.com/keras-team/keras-contrib.git && \\\n",
    "#     conda clean -yt     \n",
    "\n",
    "#ADD theanorc /home/keras/.theanorc\n",
    "\n",
    "ENV PYTHONPATH='/src/:$PYTHONPATH'\n",
    "\n",
    "WORKDIR /src\n",
    "\n",
    "EXPOSE 8888\n",
    "\n",
    "# CMD jupyter notebook --port=8888 --ip=0.0.0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'georgedockeraccount/chestxray-no-aml-gpu-root-account:1.0.4'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'./../docker/dockerfile_1.0.4'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%dotenv\n",
    "docker_image_name = os.getenv('docker_login') + os.getenv('image_tag') + ':' + os.getenv('image_version')\n",
    "docker_file_location = os.path.join(*(['.', '..','docker', dockerfile_name]))\n",
    "working_path = '.'\n",
    "\n",
    "docker_image_name\n",
    "docker_file_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ./docker_history\n",
    "!cp $docker_file_location ./docker_history/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker build -t georgedockeraccount/chestxray-no-aml-gpu-root-account:1.0.4 -f ./../docker/dockerfile_1.0.4 .\n",
      "Sending build context to Docker daemon  5.294MB\n",
      "Step 1/16 : FROM nvidia/cuda:10.0-cudnn7-devel\n",
      " ---> eaf2ceb9de1a\n",
      "Step 2/16 : MAINTAINER George Iordanescu <ghiordan@microsoft.com>\n",
      " ---> Using cache\n",
      " ---> 44abab7bfae5\n",
      "Step 3/16 : RUN apt-get update && apt-get install -y --no-install-recommends       apt-utils       bzip2       g++       git       graphviz       libgl1-mesa-glx       libhdf5-dev       openmpi-bin       wget       ssh       rsync &&     rm -rf /var/lib/apt/lists/*\n",
      " ---> Using cache\n",
      " ---> c5fb82908d50\n",
      "Step 4/16 : ENV CONDA_DIR /opt/conda\n",
      " ---> Using cache\n",
      " ---> d4d519c56f2b\n",
      "Step 5/16 : ENV PATH $CONDA_DIR/bin:$PATH\n",
      " ---> Using cache\n",
      " ---> 31aa9364de4c\n",
      "Step 6/16 : RUN wget --quiet --no-check-certificate https://repo.continuum.io/miniconda/Miniconda3-4.2.12-Linux-x86_64.sh &&     echo \"c59b3dd3cad550ac7596e0d599b91e75d88826db132e4146030ef471bb434e9a *Miniconda3-4.2.12-Linux-x86_64.sh\" | sha256sum -c - &&     /bin/bash /Miniconda3-4.2.12-Linux-x86_64.sh -f -b -p $CONDA_DIR &&     rm Miniconda3-4.2.12-Linux-x86_64.sh &&     echo export PATH=$CONDA_DIR/bin:'$PATH' > /etc/profile.d/conda.sh\n",
      " ---> Using cache\n",
      " ---> 7193ca6fb97b\n",
      "Step 7/16 : RUN mkdir -p /tmp/azcopy && mkdir -p /azcopy10 &&     wget -O /tmp/azcopy/azcopyv10.tar.gz https://aka.ms/downloadazcopy-v10-linux &&      tar -xf /tmp/azcopy/azcopyv10.tar.gz -C /azcopy10\n",
      " ---> Using cache\n",
      " ---> 46aef36a30ea\n",
      "Step 8/16 : RUN rm -rf /tmp/azcopy\n",
      " ---> Using cache\n",
      " ---> 84e603cd743e\n",
      "Step 9/16 : ENV PATH=/azcopy10/azcopy_linux_amd64_10.3.2:$PATH\n",
      " ---> Using cache\n",
      " ---> 4989748f7af6\n",
      "Step 10/16 : RUN mkdir -p /sr\n",
      " ---> Using cache\n",
      " ---> 470abafd210b\n",
      "Step 11/16 : ARG python_version=3.6\n",
      " ---> Using cache\n",
      " ---> 5cafe8d41e92\n",
      "Step 12/16 : RUN conda config --append channels conda-forge\n",
      " ---> Using cache\n",
      " ---> b26448135173\n",
      "Step 13/16 : RUN conda install -y python=${python_version} &&     pip install --upgrade pip &&     pip install       sklearn_pandas       tensorflow-gpu==1.14       python-dotenv       papermill[azure] &&      conda install       bcolz       h5py       imageio       matplotlib       mkl       numpy       nose       notebook       opencv       Pillow       pandas       pydot       pygpu       pyyaml       scikit-learn       scikit-image       six       theano       mkdocs       tqdm       &&     conda install pytorch torchvision cudatoolkit=9.2 -c pytorch &&     git clone git://github.com/keras-team/keras.git /src && pip install -e /src[tests] &&     pip install git+git://github.com/keras-team/keras.git &&     pip install git+https://github.com/aleju/imgaug &&     conda clean -yt\n",
      " ---> Using cache\n",
      " ---> 35f4e44c050f\n",
      "Step 14/16 : ENV PYTHONPATH='/src/:$PYTHONPATH'\n",
      " ---> Using cache\n",
      " ---> 829a1f185764\n",
      "Step 15/16 : WORKDIR /src\n",
      " ---> Using cache\n",
      " ---> aef3d8630fa9\n",
      "Step 16/16 : EXPOSE 8888\n",
      " ---> Using cache\n",
      " ---> d001c6ce5882\n",
      "Successfully built d001c6ce5882\n",
      "Successfully tagged georgedockeraccount/chestxray-no-aml-gpu-root-account:1.0.4\n"
     ]
    }
   ],
   "source": [
    "!echo docker build -t $docker_image_name -f $docker_file_location $working_path\n",
    "!docker build -t $docker_image_name -f $docker_file_location $working_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' /bin/bash -c \"conda env list; pwd; ls -l /workspace ; pip3 list | grep tensorflow;python -c \\'import tensorflow as tf; from tensorflow.python.client import device_lib; print(tf.__version__);gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.1);sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options));local_device_protos = device_lib.list_local_devices(); print( [x.name for x in local_device_protos if x.device_type == \\\\\"GPU\\\\\"]); sess.close() \\';\"'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'docker run --gpus all -it --rm  --name chestxray-no-aml-gpu_docker_container -v $(pwd):/workspace:rw georgedockeraccount/chestxray-no-aml-gpu-root-account:1.0.4 /bin/bash -c \"conda env list; pwd; ls -l /workspace ; pip3 list | grep tensorflow;python -c \\'import tensorflow as tf; from tensorflow.python.client import device_lib; print(tf.__version__);gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.1);sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options));local_device_protos = device_lib.list_local_devices(); print( [x.name for x in local_device_protos if x.device_type == \\\\\"GPU\\\\\"]); sess.close() \\';\"'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\n",
      "#\n",
      "base                  *  /opt/conda\n",
      "\n",
      "/src\n",
      "total 788\n",
      "-rw-rw-r-- 1 1003 1003   7566 Nov 16 22:44 000_setup_azure_sa.ipynb\n",
      "-rwxrwxr-x 1 1003 1003 473751 Nov 16 22:43 00_create_docker_image.html\n",
      "-rwxrwxr-x 1 1003 1003  37116 Nov 16 22:44 010_create_training_docker_image.ipynb\n",
      "drwxrwxr-x 5 1003 1003   4096 Nov 16 22:12 01_DataPrep\n",
      "drwxrwxr-x 2 1003 1003   4096 Nov 14 11:30 02_Model\n",
      "drwxrwxr-x 2 1003 1003   4096 Nov 14 11:53 docker_history\n",
      "-rwxrwxr-x 1 1003 1003 256521 Nov 16 04:29 edit_python_files.html\n",
      "-rwxrwxr-x 1 1003 1003   7152 Nov 16 04:30 edit_python_files.ipynb\n",
      "drwxrwxr-x 3 1003 1003   4096 Nov 15 04:58 src\n",
      "tensorflow-estimator   1.14.0      \n",
      "tensorflow-gpu         1.14.0      \n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "1.14.0\n",
      "2019-11-16 22:44:37.377728: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-11-16 22:44:37.385570: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
      "2019-11-16 22:44:37.653951: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56500617d230 executing computations on platform CUDA. Devices:\n",
      "2019-11-16 22:44:37.653994: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
      "2019-11-16 22:44:37.654008: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (1): Tesla K80, Compute Capability 3.7\n",
      "2019-11-16 22:44:37.656542: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2596990000 Hz\n",
      "2019-11-16 22:44:37.658689: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5650061f63c0 executing computations on platform Host. Devices:\n",
      "2019-11-16 22:44:37.658715: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2019-11-16 22:44:37.659403: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
      "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
      "pciBusID: 5730:00:00.0\n",
      "2019-11-16 22:44:37.659886: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties: \n",
      "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
      "pciBusID: 71e1:00:00.0\n",
      "2019-11-16 22:44:37.660247: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
      "2019-11-16 22:44:37.661673: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
      "2019-11-16 22:44:37.662923: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
      "2019-11-16 22:44:37.663279: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
      "2019-11-16 22:44:37.664891: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2019-11-16 22:44:37.666750: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2019-11-16 22:44:37.670696: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
      "2019-11-16 22:44:37.672554: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1\n",
      "2019-11-16 22:44:37.672605: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
      "2019-11-16 22:44:37.676798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-11-16 22:44:37.676826: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 1 \n",
      "2019-11-16 22:44:37.676839: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N N \n",
      "2019-11-16 22:44:37.676849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 1:   N N \n",
      "2019-11-16 22:44:37.678675: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1144 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 5730:00:00.0, compute capability: 3.7)\n",
      "2019-11-16 22:44:37.679670: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 1144 MB memory) -> physical GPU (device: 1, name: Tesla K80, pci bus id: 71e1:00:00.0, compute capability: 3.7)\n",
      "2019-11-16 22:44:37.682799: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
      "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
      "pciBusID: 5730:00:00.0\n",
      "2019-11-16 22:44:37.683306: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties: \n",
      "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
      "pciBusID: 71e1:00:00.0\n",
      "2019-11-16 22:44:37.683347: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-16 22:44:37.683383: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\r\n",
      "2019-11-16 22:44:37.683407: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\r\n",
      "2019-11-16 22:44:37.683429: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\r\n",
      "2019-11-16 22:44:37.683449: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\r\n",
      "2019-11-16 22:44:37.683471: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\r\n",
      "2019-11-16 22:44:37.683495: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\r\n",
      "2019-11-16 22:44:37.685245: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1\r\n",
      "2019-11-16 22:44:37.685300: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n",
      "2019-11-16 22:44:37.685317: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 1 \r\n",
      "2019-11-16 22:44:37.685329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N N \r\n",
      "2019-11-16 22:44:37.685338: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 1:   N N \r\n",
      "2019-11-16 22:44:37.687043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/device:GPU:0 with 1144 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 5730:00:00.0, compute capability: 3.7)\r\n",
      "2019-11-16 22:44:37.687533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/device:GPU:1 with 1144 MB memory) -> physical GPU (device: 1, name: Tesla K80, pci bus id: 71e1:00:00.0, compute capability: 3.7)\r\n",
      "['/device:GPU:0', '/device:GPU:1']\r\n"
     ]
    }
   ],
   "source": [
    "cli_command_inside_container=' /bin/bash -c \"conda env list; pwd; ls -l /workspace ; ' + \\\n",
    "    'pip3 list | grep tensorflow;' + \\\n",
    "    'python -c \\'import tensorflow as tf; ' +\\\n",
    "    'from tensorflow.python.client import device_lib; ' +\\\n",
    "    'print(tf.__version__);' +\\\n",
    "    'gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.1);' +\\\n",
    "    'sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options));' +\\\n",
    "    'local_device_protos = device_lib.list_local_devices(); ' +\\\n",
    "    'print( [x.name for x in local_device_protos if x.device_type == \\\\\"GPU\\\\\"]); ' +\\\n",
    "    'sess.close() ' +\\\n",
    "    '\\';' +\\\n",
    "    '\"'\n",
    "\n",
    "\n",
    "\n",
    "cli_command_inside_container\n",
    "\n",
    "cli_command='docker run --gpus all -it --rm  --name chestxray-no-aml-gpu_docker_container ' + \\\n",
    "'-v $(pwd):/workspace:rw ' + \\\n",
    "docker_image_name + \\\n",
    "cli_command_inside_container\n",
    "\n",
    "cli_command\n",
    "!$cli_command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/loginvm022/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n"
     ]
    }
   ],
   "source": [
    "cli_command = 'docker login  --username '+ os.getenv('docker_login') +' --password '+os.getenv('docker_password')\n",
    "# cli_command\n",
    "!$cli_command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The push refers to repository [docker.io/georgedockeraccount/chestxray-no-aml-gpu-root-account]\n",
      "\n",
      "\u001b[1B0486be30: Preparing \n",
      "\u001b[1B3da388b2: Preparing \n",
      "\u001b[1B8903c2e8: Preparing \n",
      "\u001b[1Bb4fea62e: Preparing \n",
      "\u001b[1B5a905024: Preparing \n",
      "\u001b[1B5f137119: Preparing \n",
      "\u001b[1B3ee3c5e1: Preparing \n",
      "\u001b[1Bd5e86d56: Preparing \n",
      "\u001b[1Bfa18caaf: Preparing \n",
      "\u001b[1Bd8b4edec: Preparing \n",
      "\u001b[1Bbdc0b45f: Preparing \n",
      "\u001b[1Bde7ea906: Preparing \n",
      "\u001b[1B7a55184c: Preparing \n",
      "\u001b[9B5f137119: Waiting g \n",
      "\u001b[1B13bce073: Preparing \n",
      "\u001b[1Be43028b3: Preparing \n",
      "\u001b[1Bf3abed5f: Layer already exists \u001b[15A\u001b[2K\u001b[12A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K1.0.4: digest: sha256:91f9efe779740f75ad626b94b6bb25c96d186eac9e53dd3b8bef61cdcf602cae size: 3891\n"
     ]
    }
   ],
   "source": [
    "!docker push $docker_image_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook 010_create_training_docker_image.ipynb to html\n",
      "[NbConvertApp] Writing 290232 bytes to 010_create_training_docker_image.html\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to html 010_create_training_docker_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
