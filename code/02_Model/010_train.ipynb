{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "##### Copyright (C) Microsoft Corporation.  \n",
    "see license file for details "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow multiple displays per cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/local_dir/prj/AzureChestXRayNoAML/code/02_Model/../../../..'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AZUREML_NATIVE_SHARE_DIRECTORY mapping to host dir is set by _nativeSharedDirectory_ in .compute file \n",
    "\n",
    "import os\n",
    "baseDataDir =  os.path.join(os.getcwd(), os.path.join(*(['..', '..', '..', '..'])))\n",
    "baseDataDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import utlity functions\n",
    "\n",
    "import sys, os\n",
    "paths_to_append = [os.path.join(os.getcwd(), os.path.join(*([ '..', 'src'])))]\n",
    "def add_path_to_sys_path(path_to_append):\n",
    "    if not (any(path_to_append in paths for paths in sys.path)):\n",
    "        sys.path.append(path_to_append)\n",
    "[add_path_to_sys_path(crt_path) for crt_path in paths_to_append]\n",
    "\n",
    "import azure_chestxray_utils\n",
    "# import azure_chestxray_keras_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the file path variables \n",
    "# paths are tipically container level dirs mapped to a host dir for data persistence.\n",
    "\n",
    "prj_consts = azure_chestxray_utils.chestxray_consts()\n",
    "\n",
    " \n",
    "data_base_input_dir=os.path.join(baseDataDir, os.path.join(*(prj_consts.BASE_INPUT_DIR_list)))\n",
    "data_base_output_dir=os.path.join(baseDataDir, os.path.join(*(prj_consts.BASE_OUTPUT_DIR_list))) \n",
    "\n",
    "# data used for training\n",
    "nih_chest_xray_data_dir=os.path.join(data_base_input_dir, \n",
    "                                     os.path.join(*(prj_consts.ChestXray_IMAGES_DIR_list+['images'])))\n",
    "\n",
    "data_partitions_dir=os.path.join(data_base_output_dir, os.path.join(*(prj_consts.DATA_PARTITIONS_DIR_list))) \n",
    "\n",
    "partition_path = os.path.join(data_partitions_dir, 'partition14_unormalized_cleaned.pickle')\n",
    "label_path = os.path.join(data_partitions_dir,'labels14_unormalized_cleaned.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/local_dir/prj/AzureChestXRayNoAML/code/02_Model/../../../../data/chestxray/output/weights_tmpdir'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 613208\r\n",
      "-rw-r--r-- 1 root root 29897304 May 24 06:26 azure_chest_xray_14_weights_712split_epoch_001_val_loss_218.5087.hdf5\r\n",
      "-rw-r--r-- 1 root root 29897304 May 24 13:24 azure_chest_xray_14_weights_712split_epoch_001_val_loss_293.1064.hdf5\r\n",
      "-rw-r--r-- 1 root root 29897304 May 24 13:00 azure_chest_xray_14_weights_712split_epoch_001_val_loss_351.0278.hdf5\r\n",
      "-rw-r--r-- 1 root root 29897304 May 24 06:33 azure_chest_xray_14_weights_712split_epoch_002_val_loss_222.5165.hdf5\r\n",
      "-rw-r--r-- 1 root root 29897304 May 24 13:31 azure_chest_xray_14_weights_712split_epoch_002_val_loss_310.3925.hdf5\r\n",
      "-rw-r--r-- 1 root root 29897304 May 24 13:37 azure_chest_xray_14_weights_712split_epoch_003_val_loss_348.3476.hdf5\r\n",
      "-rw-r--r-- 1 root root 29897304 May 24 13:43 azure_chest_xray_14_weights_712split_epoch_004_val_loss_383.9522.hdf5\r\n",
      "-rw-r--r-- 1 root root 29897304 May 24 13:49 azure_chest_xray_14_weights_712split_epoch_005_val_loss_254.2308.hdf5\r\n",
      "-rw-r--r-- 1 root root 29897304 May 24 13:55 azure_chest_xray_14_weights_712split_epoch_006_val_loss_256.7298.hdf5\r\n",
      "-rw-r--r-- 1 root root 29897304 May 24 14:02 azure_chest_xray_14_weights_712split_epoch_007_val_loss_251.7269.hdf5\r\n",
      "-rw-r--r-- 1 root root 29897304 May 24 14:08 azure_chest_xray_14_weights_712split_epoch_008_val_loss_250.6545.hdf5\r\n",
      "-rw-r--r-- 1 root root 29897304 May 24 14:14 azure_chest_xray_14_weights_712split_epoch_009_val_loss_248.6482.hdf5\r\n",
      "-rw-r--r-- 1 root root 29897304 May 24 14:20 azure_chest_xray_14_weights_712split_epoch_010_val_loss_248.3432.hdf5\r\n",
      "-rw-r--r-- 1 root root 29897304 May 24 14:27 azure_chest_xray_14_weights_712split_epoch_011_val_loss_248.2310.hdf5\r\n",
      "-rw-r--r-- 1 root root 29897304 May 24 14:33 azure_chest_xray_14_weights_712split_epoch_012_val_loss_247.3143.hdf5\r\n",
      "-rw-r--r-- 1 root root 29897304 May 24 14:39 azure_chest_xray_14_weights_712split_epoch_013_val_loss_245.8204.hdf5\r\n",
      "-rw-r--r-- 1 root root 29897304 May 24 14:45 azure_chest_xray_14_weights_712split_epoch_014_val_loss_248.9458.hdf5\r\n",
      "-rw-r--r-- 1 root root 29897304 May 24 14:52 azure_chest_xray_14_weights_712split_epoch_015_val_loss_245.8470.hdf5\r\n",
      "-rw-r--r-- 1 root root 29897304 May 24 14:58 azure_chest_xray_14_weights_712split_epoch_016_val_loss_246.7685.hdf5\r\n",
      "-rw-r--r-- 1 root root 29897304 May 24 15:04 azure_chest_xray_14_weights_712split_epoch_017_val_loss_242.2513.hdf5\r\n",
      "-rw-r--r-- 1 root root 29897304 May 24 15:11 azure_chest_xray_14_weights_712split_epoch_018_val_loss_241.8930.hdf5\r\n"
     ]
    }
   ],
   "source": [
    "# global variables\n",
    "\n",
    "weights_dir = os.path.join(data_base_output_dir, os.path.join(*(prj_consts.MODEL_WEIGHTS_DIR_list))) \n",
    "!mkdir -p {weights_dir}\n",
    "weights_dir\n",
    "!ls -l {weights_dir}\n",
    "\n",
    "# weights_path = os.path.join(\n",
    "#     weights_dir, \n",
    "#     prj_consts.PRETRAINED_DENSENET201_IMAGENET_CHESTXRAY_MODEL_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "ia.seed(1)\n",
    "\n",
    "import cv2\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, Callback, ModelCheckpoint\n",
    "import numpy as np\n",
    "import pickle\n",
    "from keras_contrib.applications.densenet import DenseNetImageNet121\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model\n",
    "from keras.utils import multi_gpu_model\n",
    "from tensorflow.python.client import device_lib\n",
    "import warnings\n",
    "from keras.utils import Sequence\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For testing purpose, we just run 1 epoch. It will take around 25 mins to run for one epoch using 2 K80 GPUs and it is usually needed to run around 30~50 epochs for the model to get converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make force_restart = False if you continue a previous train session, make it True to start from scratch\n",
    "force_restart = False\n",
    "\n",
    "initial_lr = 0.001\n",
    "resized_height = 224\n",
    "resized_width = 224\n",
    "# resized_height = prj_consts.CHESTXRAY_MODEL_EXPECTED_IMAGE_HEIGHT\n",
    "# resized_width = prj_consts.CHESTXRAY_MODEL_EXPECTED_IMAGE_WIDTH\n",
    "num_channel = 3\n",
    "num_classes = 14\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu_fraction = 0.4\n",
    "# gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=gpu_fraction)\n",
    "# sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_available_gpus():\n",
    "#     \"\"\"\n",
    "\n",
    "#     Returns: number of GPUs available in the system\n",
    "\n",
    "#     \"\"\"\n",
    "#     local_device_protos = device_lib.list_local_devices()\n",
    "#     return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "\n",
    "# # get number of available GPUs\n",
    "# num_gpu = len(get_available_gpus())\n",
    "num_gpu=2\n",
    "\n",
    "# keras multi_gpu_model slices the data to different GPUs. see https://keras.io/utils/#multi_gpu_model for more details.\n",
    "\n",
    "#48 # 64 seems to be too much on NC12 \n",
    "#96 is too much on 2 x Tesla P100-PCIE-16GB \n",
    "batch_size =num_gpu *  64 \n",
    "\n",
    "\n",
    "# use Keras multi-gpu model, so we need to make sure the batch_size is divisible by num_gpu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device_lib.list_local_devices()\n",
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Keras multi-gpu model, so we need to make sure the batch_size is divisible by num_gpu.\n",
    "\n",
    "# multi GPU model checkpoint. copied from https://github.com/keras-team/keras/issues/8463\n",
    "class MultiGPUCheckpointCallback(Callback):\n",
    "\n",
    "    def __init__(self, filepath, base_model, monitor='val_loss', verbose=0,\n",
    "                 save_best_only=False, save_weights_only=False,\n",
    "                 mode='auto', period=1):\n",
    "        super(MultiGPUCheckpointCallback, self).__init__()\n",
    "        self.base_model = base_model\n",
    "        self.monitor = monitor\n",
    "        self.verbose = verbose\n",
    "        self.filepath = filepath\n",
    "        self.save_best_only = save_best_only\n",
    "        self.save_weights_only = save_weights_only\n",
    "        self.period = period\n",
    "        self.epochs_since_last_save = 0\n",
    "\n",
    "        if mode not in ['auto', 'min', 'max']:\n",
    "            warnings.warn('ModelCheckpoint mode %s is unknown, '\n",
    "                          'fallback to auto mode.' % (mode),\n",
    "                          RuntimeWarning)\n",
    "            mode = 'auto'\n",
    "\n",
    "        if mode == 'min':\n",
    "            self.monitor_op = np.less\n",
    "            self.best = np.Inf\n",
    "        elif mode == 'max':\n",
    "            self.monitor_op = np.greater\n",
    "            self.best = -np.Inf\n",
    "        else:\n",
    "            if 'acc' in self.monitor or self.monitor.startswith('fmeasure'):\n",
    "                self.monitor_op = np.greater\n",
    "                self.best = -np.Inf\n",
    "            else:\n",
    "                self.monitor_op = np.less\n",
    "                self.best = np.Inf\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        self.epochs_since_last_save += 1\n",
    "        if self.epochs_since_last_save >= self.period:\n",
    "            self.epochs_since_last_save = 0\n",
    "            filepath = self.filepath.format(epoch=epoch + 1, **logs)\n",
    "            if self.save_best_only:\n",
    "                current = logs.get(self.monitor)\n",
    "                if current is None:\n",
    "                    warnings.warn('Can save best model only with %s available, '\n",
    "                                  'skipping.' % (self.monitor), RuntimeWarning)\n",
    "                else:\n",
    "                    if self.monitor_op(current, self.best):\n",
    "                        if self.verbose > 0:\n",
    "                            print('Epoch %05d: %s improved from %0.5f to %0.5f,'\n",
    "                                  ' saving model to %s'\n",
    "                                  % (epoch + 1, self.monitor, self.best,\n",
    "                                     current, filepath))\n",
    "                        self.best = current\n",
    "                        if self.save_weights_only:\n",
    "                            self.base_model.save_weights(filepath, overwrite=True)\n",
    "                        else:\n",
    "                            self.base_model.save(filepath, overwrite=True)\n",
    "                    else:\n",
    "                        if self.verbose > 0:\n",
    "                            print('Epoch %05d: %s did not improve' %\n",
    "                                  (epoch + 1, self.monitor))\n",
    "            else:\n",
    "                if self.verbose > 0:\n",
    "                    print('Epoch %05d: saving model to %s' % (epoch + 1, filepath))\n",
    "                if self.save_weights_only:\n",
    "                    self.base_model.save_weights(filepath, overwrite=True)\n",
    "                else:\n",
    "                    self.base_model.save(filepath, overwrite=True)\n",
    "\n",
    "\n",
    "seq = iaa.Sequential([\n",
    "    iaa.Fliplr(0.5),  # horizontal flips\n",
    "    iaa.Affine(rotate=(-15, 15)),  # random rotate image\n",
    "    iaa.Affine(scale=(0.8, 1.1)),  # randomly scale the image\n",
    "], random_order=True)  # apply augmenters in random order\n",
    "\n",
    "\n",
    "# generator for train and validation data\n",
    "# use the Sequence class per issue https://github.com/keras-team/keras/issues/1638\n",
    "class DataGenSequence(Sequence):\n",
    "    def __init__(self, labels, image_file_index, current_state):\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.img_file_index = image_file_index\n",
    "        self.current_state = current_state\n",
    "        self.len = len(self.img_file_index) // self.batch_size\n",
    "        print(\"for DataGenSequence\", current_state, \"total rows are:\", len(self.img_file_index), \", len is\", self.len)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # print(\"loading data segmentation\", idx)\n",
    "        # make sure each batch size has the same amount of data\n",
    "        current_batch = self.img_file_index[idx * self.batch_size: (idx + 1) * self.batch_size]\n",
    "        X = np.empty((self.batch_size, resized_height, resized_width, num_channel))\n",
    "        y = np.empty((self.batch_size, num_classes))\n",
    "\n",
    "        for i, image_name in enumerate(current_batch):\n",
    "            path = os.path.join(nih_chest_xray_data_dir, image_name)\n",
    "            # loading data\n",
    "\n",
    "            img = cv2.resize(cv2.imread(path), (resized_height, resized_width)).astype(np.float32)\n",
    "            X[i, :, :, :] = img\n",
    "            y[i, :] = labels[image_name]\n",
    "\n",
    "            # only do random flipping in training status\n",
    "        if self.current_state == 'train':\n",
    "            x_augmented = seq.augment_images(X)\n",
    "        else:\n",
    "            x_augmented = X\n",
    "\n",
    "        return x_augmented, y\n",
    "\n",
    "\n",
    "# loss function\n",
    "def unweighted_binary_crossentropy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        y_true: true labels\n",
    "        y_pred: predicted labels\n",
    "\n",
    "    Returns: the sum of binary cross entropy loss across all the classes\n",
    "\n",
    "    \"\"\"\n",
    "    return K.sum(K.binary_crossentropy(y_true, y_pred))\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    \"\"\"\n",
    "\n",
    "    Returns: a model with specified weights\n",
    "\n",
    "    \"\"\"\n",
    "    # define the model, use pre-trained weights for image_net\n",
    "    base_model = DenseNetImageNet121(input_shape=(224, 224, 3),\n",
    "                                     weights='imagenet',\n",
    "                                     include_top=False,\n",
    "                                     pooling='avg')\n",
    "\n",
    "    x = base_model.output\n",
    "    predictions = Dense(14, activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using 2 GPUs\n"
     ]
    }
   ],
   "source": [
    "if num_gpu > 1:\n",
    "    print(\"using\", num_gpu, \"GPUs\")\n",
    "    # build model\n",
    "    with tf.device('/cpu:0'):\n",
    "        model_single_gpu = build_model()\n",
    "    # model_single_gpu.load_weights(weights_path)\n",
    "\n",
    "    # convert to multi-gpu model\n",
    "    model_multi_gpu = multi_gpu_model(model_single_gpu, gpus=num_gpu)\n",
    "    model_checkpoint = MultiGPUCheckpointCallback(\n",
    "        os.path.join(weights_dir, 'azure_chest_xray_14_weights_712split_epoch_{epoch:03d}_val_loss_{val_loss:.4f}.hdf5'),\n",
    "        model_single_gpu, monitor='val_loss', save_weights_only=True)\n",
    "\n",
    "    \n",
    "\n",
    "else:\n",
    "    print(\"using single GPU\")\n",
    "    model_multi_gpu = build_model()\n",
    "    model_checkpoint = ModelCheckpoint(\n",
    "        os.path.join(weights_dir, 'azure_chest_xray_14_weights_712split_epoch_{epoch:03d}_val_loss_{val_loss:.4f}.hdf5'),\n",
    "        monitor='val_loss', save_weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = num_gpu*2 #*10\n",
    "\n",
    "model_multi_gpu.compile(optimizer=Adam(lr=initial_lr), loss=unweighted_binary_crossentropy)\n",
    "\n",
    "reduce_lr_on_plateau = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1, min_lr=1e-6)\n",
    "\n",
    "callbacks = [model_checkpoint, reduce_lr_on_plateau]\n",
    "\n",
    "with open(label_path, 'rb') as f:\n",
    "    labels = pickle.load(f)\n",
    "\n",
    "with open(partition_path, 'rb') as f:\n",
    "    partition = pickle.load(f)\n",
    "\n",
    "model_multi_gpu.fit_generator(generator=DataGenSequence(labels, partition['train'], current_state='train'),\n",
    "                              epochs=epochs,\n",
    "                              verbose=1,\n",
    "                              callbacks=callbacks,\n",
    "                              workers=num_workers,\n",
    "                              # max_queue_size=32,\n",
    "                              # shuffle=False,\n",
    "                              validation_data=DataGenSequence(labels, partition['valid'], current_state='validation')\n",
    "                              # validation_steps=1\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to html 010_train.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
