{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "##### Copyright (C) Microsoft Corporation.  \n",
    "see license file for details "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow multiple displays per cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import utlity functions\n",
    "\n",
    "paths_to_append = [os.path.join(os.getcwd(), os.path.join(*([ '..', 'src'])))]\n",
    "def add_path_to_sys_path(path_to_append):\n",
    "    if not (any(path_to_append in paths for paths in sys.path)):\n",
    "        sys.path.append(path_to_append)\n",
    "[add_path_to_sys_path(crt_path) for crt_path in paths_to_append]\n",
    "\n",
    "import azure_chestxray_utils\n",
    "# import azure_chestxray_keras_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prj_consts = azure_chestxray_utils.chestxray_consts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data_dir/chestxray/ChestX-ray8'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'/data_dir/chestxray/output'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'/data_dir/chestxray/ChestX-ray8/ChestXray-NIHCC/images'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'/data_dir/chestxray/output/data_partitions'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'/data_dir/chestxray/output/data_partitions/partition14_unormalized_cleaned.pickle'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'/data_dir/chestxray/output/data_partitions/labels14_unormalized_cleaned.pickle'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the file path variables \n",
    "# paths are tipically container level dirs mapped to a host dir for data persistence.\n",
    " \n",
    "data_base_input_dir=os.path.join(os.path.join(*([os.sep]+prj_consts.BASE_INPUT_DIR_list)))\n",
    "data_base_output_dir=os.path.join( os.path.join(*([os.sep]+prj_consts.BASE_OUTPUT_DIR_list)))  \n",
    "\n",
    "data_base_input_dir\n",
    "data_base_output_dir\n",
    "\n",
    "# data used for training\n",
    "nih_chest_xray_data_dir=os.path.join(data_base_input_dir, \n",
    "                                     os.path.join(*(prj_consts.ChestXray_IMAGES_DIR_list+['images'])))\n",
    "\n",
    "data_partitions_dir=os.path.join(data_base_output_dir, os.path.join(*(prj_consts.DATA_PARTITIONS_DIR_list))) \n",
    "\n",
    "partition_path = os.path.join(data_partitions_dir, 'partition14_unormalized_cleaned.pickle')\n",
    "label_path = os.path.join(data_partitions_dir,'labels14_unormalized_cleaned.pickle')\n",
    "\n",
    "nih_chest_xray_data_dir\n",
    "data_partitions_dir\n",
    "partition_path\n",
    "label_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data_dir/chestxray/output/weights_tmpdir'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2861608\r\n",
      "-rw-r--r-- 1 root root 29899376 Nov 18 19:28 azure_chest_xray_14_weights_712split_epoch_001_val_loss_295.8261.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 05:03 azure_chest_xray_14_weights_712split_epoch_001_val_loss_352.4815.hdf5\r\n",
      "-rw-r--r-- 1 root root 29899376 Nov 18 19:37 azure_chest_xray_14_weights_712split_epoch_002_val_loss_305.5259.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 05:12 azure_chest_xray_14_weights_712split_epoch_002_val_loss_368.7296.hdf5\r\n",
      "-rw-r--r-- 1 root root 29899376 Nov 18 19:45 azure_chest_xray_14_weights_712split_epoch_003_val_loss_294.1529.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 05:21 azure_chest_xray_14_weights_712split_epoch_003_val_loss_372.0947.hdf5\r\n",
      "-rw-r--r-- 1 root root 29899376 Nov 18 19:54 azure_chest_xray_14_weights_712split_epoch_004_val_loss_300.9492.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 05:30 azure_chest_xray_14_weights_712split_epoch_004_val_loss_337.1455.hdf5\r\n",
      "-rw-r--r-- 1 root root 29899376 Nov 18 20:03 azure_chest_xray_14_weights_712split_epoch_005_val_loss_292.9090.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 05:39 azure_chest_xray_14_weights_712split_epoch_005_val_loss_326.6270.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 05:48 azure_chest_xray_14_weights_712split_epoch_006_val_loss_340.3534.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 05:57 azure_chest_xray_14_weights_712split_epoch_007_val_loss_324.0370.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 06:06 azure_chest_xray_14_weights_712split_epoch_008_val_loss_330.2368.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 06:15 azure_chest_xray_14_weights_712split_epoch_009_val_loss_330.4678.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 06:24 azure_chest_xray_14_weights_712split_epoch_010_val_loss_334.7676.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 06:33 azure_chest_xray_14_weights_712split_epoch_011_val_loss_309.5192.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 06:42 azure_chest_xray_14_weights_712split_epoch_012_val_loss_306.4389.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 06:51 azure_chest_xray_14_weights_712split_epoch_013_val_loss_303.4832.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 07:00 azure_chest_xray_14_weights_712split_epoch_014_val_loss_308.8400.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 07:08 azure_chest_xray_14_weights_712split_epoch_015_val_loss_302.2931.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 07:17 azure_chest_xray_14_weights_712split_epoch_016_val_loss_312.9073.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 07:26 azure_chest_xray_14_weights_712split_epoch_017_val_loss_306.3693.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 07:35 azure_chest_xray_14_weights_712split_epoch_018_val_loss_303.0279.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 07:44 azure_chest_xray_14_weights_712split_epoch_019_val_loss_302.5577.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 07:53 azure_chest_xray_14_weights_712split_epoch_020_val_loss_303.1216.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 08:02 azure_chest_xray_14_weights_712split_epoch_021_val_loss_301.7447.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 08:11 azure_chest_xray_14_weights_712split_epoch_022_val_loss_301.0271.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 08:20 azure_chest_xray_14_weights_712split_epoch_023_val_loss_301.7991.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 08:29 azure_chest_xray_14_weights_712split_epoch_024_val_loss_302.6609.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 08:38 azure_chest_xray_14_weights_712split_epoch_025_val_loss_301.4780.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 04:11 azure_chest_xray_14_weights_712split_epoch_025_val_loss_308.5260.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 08:47 azure_chest_xray_14_weights_712split_epoch_026_val_loss_301.9127.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 08:56 azure_chest_xray_14_weights_712split_epoch_027_val_loss_301.9239.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 09:05 azure_chest_xray_14_weights_712split_epoch_028_val_loss_301.2733.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 09:14 azure_chest_xray_14_weights_712split_epoch_029_val_loss_301.6439.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 09:23 azure_chest_xray_14_weights_712split_epoch_030_val_loss_301.9176.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 09:32 azure_chest_xray_14_weights_712split_epoch_031_val_loss_301.9887.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 09:41 azure_chest_xray_14_weights_712split_epoch_032_val_loss_301.5260.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 09:50 azure_chest_xray_14_weights_712split_epoch_033_val_loss_301.7922.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 09:59 azure_chest_xray_14_weights_712split_epoch_034_val_loss_302.1005.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 10:08 azure_chest_xray_14_weights_712split_epoch_035_val_loss_301.4726.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 10:17 azure_chest_xray_14_weights_712split_epoch_036_val_loss_301.3912.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 10:26 azure_chest_xray_14_weights_712split_epoch_037_val_loss_302.3871.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 10:35 azure_chest_xray_14_weights_712split_epoch_038_val_loss_301.7152.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 10:44 azure_chest_xray_14_weights_712split_epoch_039_val_loss_301.7747.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 10:53 azure_chest_xray_14_weights_712split_epoch_040_val_loss_302.0042.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 11:01 azure_chest_xray_14_weights_712split_epoch_041_val_loss_301.4957.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 11:10 azure_chest_xray_14_weights_712split_epoch_042_val_loss_301.8978.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 11:19 azure_chest_xray_14_weights_712split_epoch_043_val_loss_301.4772.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 11:28 azure_chest_xray_14_weights_712split_epoch_044_val_loss_301.5841.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 11:37 azure_chest_xray_14_weights_712split_epoch_045_val_loss_301.5856.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 11:46 azure_chest_xray_14_weights_712split_epoch_046_val_loss_301.6686.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 11:55 azure_chest_xray_14_weights_712split_epoch_047_val_loss_301.6114.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 12:04 azure_chest_xray_14_weights_712split_epoch_048_val_loss_301.6864.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 12:13 azure_chest_xray_14_weights_712split_epoch_049_val_loss_301.7654.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 12:22 azure_chest_xray_14_weights_712split_epoch_050_val_loss_301.8718.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 12:31 azure_chest_xray_14_weights_712split_epoch_051_val_loss_302.1028.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 12:40 azure_chest_xray_14_weights_712split_epoch_052_val_loss_301.8749.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 12:49 azure_chest_xray_14_weights_712split_epoch_053_val_loss_301.6866.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 12:58 azure_chest_xray_14_weights_712split_epoch_054_val_loss_301.8586.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 13:07 azure_chest_xray_14_weights_712split_epoch_055_val_loss_302.2449.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 13:16 azure_chest_xray_14_weights_712split_epoch_056_val_loss_301.8713.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 13:25 azure_chest_xray_14_weights_712split_epoch_057_val_loss_301.6646.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 13:34 azure_chest_xray_14_weights_712split_epoch_058_val_loss_301.6565.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 13:42 azure_chest_xray_14_weights_712split_epoch_059_val_loss_301.7063.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 13:51 azure_chest_xray_14_weights_712split_epoch_060_val_loss_301.7149.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 14:00 azure_chest_xray_14_weights_712split_epoch_061_val_loss_301.9853.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 14:09 azure_chest_xray_14_weights_712split_epoch_062_val_loss_301.8531.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 14:18 azure_chest_xray_14_weights_712split_epoch_063_val_loss_302.1150.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 14:27 azure_chest_xray_14_weights_712split_epoch_064_val_loss_301.3672.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 14:36 azure_chest_xray_14_weights_712split_epoch_065_val_loss_301.7707.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 14:45 azure_chest_xray_14_weights_712split_epoch_066_val_loss_302.0367.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 14:54 azure_chest_xray_14_weights_712split_epoch_067_val_loss_301.5545.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 15:03 azure_chest_xray_14_weights_712split_epoch_068_val_loss_301.6365.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 15:12 azure_chest_xray_14_weights_712split_epoch_069_val_loss_302.0896.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 15:21 azure_chest_xray_14_weights_712split_epoch_070_val_loss_301.4237.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 15:30 azure_chest_xray_14_weights_712split_epoch_071_val_loss_301.2142.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 15:39 azure_chest_xray_14_weights_712split_epoch_072_val_loss_301.7701.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 15:48 azure_chest_xray_14_weights_712split_epoch_073_val_loss_301.9578.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 15:56 azure_chest_xray_14_weights_712split_epoch_074_val_loss_301.9366.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 16:05 azure_chest_xray_14_weights_712split_epoch_075_val_loss_301.5968.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 16:14 azure_chest_xray_14_weights_712split_epoch_076_val_loss_301.6227.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 16:23 azure_chest_xray_14_weights_712split_epoch_077_val_loss_301.7352.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 16:32 azure_chest_xray_14_weights_712split_epoch_078_val_loss_301.7758.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 16:41 azure_chest_xray_14_weights_712split_epoch_079_val_loss_301.3334.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 16:50 azure_chest_xray_14_weights_712split_epoch_080_val_loss_301.5130.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 16:59 azure_chest_xray_14_weights_712split_epoch_081_val_loss_301.6434.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 17:08 azure_chest_xray_14_weights_712split_epoch_082_val_loss_301.5004.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 17:17 azure_chest_xray_14_weights_712split_epoch_083_val_loss_301.6529.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 17:26 azure_chest_xray_14_weights_712split_epoch_084_val_loss_301.3717.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 17:35 azure_chest_xray_14_weights_712split_epoch_085_val_loss_301.7495.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 17:43 azure_chest_xray_14_weights_712split_epoch_086_val_loss_301.7652.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 17:52 azure_chest_xray_14_weights_712split_epoch_087_val_loss_301.8319.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 18:01 azure_chest_xray_14_weights_712split_epoch_088_val_loss_301.4532.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 18:10 azure_chest_xray_14_weights_712split_epoch_089_val_loss_301.7781.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 18:19 azure_chest_xray_14_weights_712split_epoch_090_val_loss_301.3073.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 18:28 azure_chest_xray_14_weights_712split_epoch_091_val_loss_301.5048.hdf5\r\n",
      "-rwxrwxrwx 1 root root 29899376 Nov 18 18:37 azure_chest_xray_14_weights_712split_epoch_092_val_loss_301.7557.hdf5\r\n"
     ]
    }
   ],
   "source": [
    "# global variables\n",
    "\n",
    "weights_dir = os.path.join(data_base_output_dir, os.path.join(*(prj_consts.MODEL_WEIGHTS_DIR_list))) \n",
    "!mkdir -p {weights_dir}\n",
    "weights_dir\n",
    "!ls -l {weights_dir}\n",
    "\n",
    "# weights_path = os.path.join(\n",
    "#     weights_dir, \n",
    "#     prj_consts.PRETRAINED_DENSENET201_IMAGENET_CHESTXRAY_MODEL_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  # see issue #152\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "ia.seed(1)\n",
    "\n",
    "import cv2\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, Callback, ModelCheckpoint\n",
    "import numpy as np\n",
    "import pickle\n",
    "from keras_contrib.applications.densenet import DenseNetImageNet121\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model\n",
    "from keras.utils import multi_gpu_model\n",
    "from tensorflow.python.client import device_lib\n",
    "import warnings\n",
    "from keras.utils import Sequence\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For testing purpose, we just run 1 epoch. It will take around 25 mins to run for one epoch using 2 K80 GPUs and it is usually needed to run around 30~50 epochs for the model to get converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make force_restart = False if you continue a previous train session, make it True to start from scratch\n",
    "force_restart = False\n",
    "\n",
    "initial_lr = 0.001\n",
    "resized_height = 224\n",
    "resized_width = 224\n",
    "# resized_height = prj_consts.CHESTXRAY_MODEL_EXPECTED_IMAGE_HEIGHT\n",
    "# resized_width = prj_consts.CHESTXRAY_MODEL_EXPECTED_IMAGE_WIDTH\n",
    "num_channel = 3\n",
    "num_classes = 14\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu_fraction = 0.4\n",
    "# gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=gpu_fraction)\n",
    "# sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_available_gpus():\n",
    "    \"\"\"\n",
    "\n",
    "    Returns: number of GPUs available in the system\n",
    "\n",
    "    \"\"\"\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "\n",
    "# # get number of available GPUs\n",
    "num_gpu = len(get_available_gpus())\n",
    "num_gpu\n",
    "# num_gpu=2\n",
    "\n",
    "# keras multi_gpu_model slices the data to different GPUs. see https://keras.io/utils/#multi_gpu_model for more details.\n",
    "\n",
    "#48 # 64 seems to be too much on NC12 \n",
    "#96 is too much on 2 x Tesla P100-PCIE-16GB \n",
    "batch_size =num_gpu * 48 #64 #48  \n",
    "\n",
    "\n",
    "# use Keras multi-gpu model, so we need to make sure the batch_size is divisible by num_gpu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device_lib.list_local_devices()\n",
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Keras multi-gpu model, so we need to make sure the batch_size is divisible by num_gpu.\n",
    "\n",
    "# multi GPU model checkpoint. copied from https://github.com/keras-team/keras/issues/8463\n",
    "class MultiGPUCheckpointCallback(Callback):\n",
    "\n",
    "    def __init__(self, filepath, base_model, monitor='val_loss', verbose=0,\n",
    "                 save_best_only=False, save_weights_only=False,\n",
    "                 mode='auto', period=1):\n",
    "        super(MultiGPUCheckpointCallback, self).__init__()\n",
    "        self.base_model = base_model\n",
    "        self.monitor = monitor\n",
    "        self.verbose = verbose\n",
    "        self.filepath = filepath\n",
    "        self.save_best_only = save_best_only\n",
    "        self.save_weights_only = save_weights_only\n",
    "        self.period = period\n",
    "        self.epochs_since_last_save = 0\n",
    "\n",
    "        if mode not in ['auto', 'min', 'max']:\n",
    "            warnings.warn('ModelCheckpoint mode %s is unknown, '\n",
    "                          'fallback to auto mode.' % (mode),\n",
    "                          RuntimeWarning)\n",
    "            mode = 'auto'\n",
    "\n",
    "        if mode == 'min':\n",
    "            self.monitor_op = np.less\n",
    "            self.best = np.Inf\n",
    "        elif mode == 'max':\n",
    "            self.monitor_op = np.greater\n",
    "            self.best = -np.Inf\n",
    "        else:\n",
    "            if 'acc' in self.monitor or self.monitor.startswith('fmeasure'):\n",
    "                self.monitor_op = np.greater\n",
    "                self.best = -np.Inf\n",
    "            else:\n",
    "                self.monitor_op = np.less\n",
    "                self.best = np.Inf\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        self.epochs_since_last_save += 1\n",
    "        if self.epochs_since_last_save >= self.period:\n",
    "            self.epochs_since_last_save = 0\n",
    "            filepath = self.filepath.format(epoch=epoch + 1, **logs)\n",
    "            if self.save_best_only:\n",
    "                current = logs.get(self.monitor)\n",
    "                if current is None:\n",
    "                    warnings.warn('Can save best model only with %s available, '\n",
    "                                  'skipping.' % (self.monitor), RuntimeWarning)\n",
    "                else:\n",
    "                    if self.monitor_op(current, self.best):\n",
    "                        if self.verbose > 0:\n",
    "                            print('Epoch %05d: %s improved from %0.5f to %0.5f,'\n",
    "                                  ' saving model to %s'\n",
    "                                  % (epoch + 1, self.monitor, self.best,\n",
    "                                     current, filepath))\n",
    "                        self.best = current\n",
    "                        if self.save_weights_only:\n",
    "                            self.base_model.save_weights(filepath, overwrite=True)\n",
    "                        else:\n",
    "                            self.base_model.save(filepath, overwrite=True)\n",
    "                    else:\n",
    "                        if self.verbose > 0:\n",
    "                            print('Epoch %05d: %s did not improve' %\n",
    "                                  (epoch + 1, self.monitor))\n",
    "            else:\n",
    "                if self.verbose > 0:\n",
    "                    print('Epoch %05d: saving model to %s' % (epoch + 1, filepath))\n",
    "                if self.save_weights_only:\n",
    "                    self.base_model.save_weights(filepath, overwrite=True)\n",
    "                else:\n",
    "                    self.base_model.save(filepath, overwrite=True)\n",
    "\n",
    "\n",
    "seq = iaa.Sequential([\n",
    "    iaa.Fliplr(0.5),  # horizontal flips\n",
    "    iaa.Affine(rotate=(-15, 15)),  # random rotate image\n",
    "    iaa.Affine(scale=(0.8, 1.1)),  # randomly scale the image\n",
    "], random_order=True)  # apply augmenters in random order\n",
    "\n",
    "\n",
    "# generator for train and validation data\n",
    "# use the Sequence class per issue https://github.com/keras-team/keras/issues/1638\n",
    "class DataGenSequence(Sequence):\n",
    "    def __init__(self, labels, image_file_index, current_state):\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.img_file_index = image_file_index\n",
    "        self.current_state = current_state\n",
    "        self.len = len(self.img_file_index) // self.batch_size\n",
    "        print(\"for DataGenSequence\", current_state, \"total rows are:\", len(self.img_file_index), \", len is\", self.len)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # print(\"loading data segmentation\", idx)\n",
    "        # make sure each batch size has the same amount of data\n",
    "        current_batch = self.img_file_index[idx * self.batch_size: (idx + 1) * self.batch_size]\n",
    "        X = np.empty((self.batch_size, resized_height, resized_width, num_channel))\n",
    "        y = np.empty((self.batch_size, num_classes))\n",
    "\n",
    "        for i, image_name in enumerate(current_batch):\n",
    "            path = os.path.join(nih_chest_xray_data_dir, image_name)\n",
    "            # loading data\n",
    "\n",
    "            img = cv2.resize(cv2.imread(path), (resized_height, resized_width)).astype(np.float32)\n",
    "            X[i, :, :, :] = img\n",
    "            y[i, :] = labels[image_name]\n",
    "\n",
    "            # only do random flipping in training status\n",
    "        if self.current_state == 'train':\n",
    "            x_augmented = seq.augment_images(X)\n",
    "        else:\n",
    "            x_augmented = X\n",
    "\n",
    "        return x_augmented, y\n",
    "\n",
    "\n",
    "# loss function\n",
    "def unweighted_binary_crossentropy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        y_true: true labels\n",
    "        y_pred: predicted labels\n",
    "\n",
    "    Returns: the sum of binary cross entropy loss across all the classes\n",
    "\n",
    "    \"\"\"\n",
    "    return K.sum(K.binary_crossentropy(y_true, y_pred))\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    \"\"\"\n",
    "\n",
    "    Returns: a model with specified weights\n",
    "\n",
    "    \"\"\"\n",
    "    # define the model, use pre-trained weights for image_net\n",
    "    base_model = DenseNetImageNet121(input_shape=(224, 224, 3),\n",
    "                                     weights='imagenet',\n",
    "                                     include_top=False,\n",
    "                                     pooling='avg')\n",
    "\n",
    "    x = base_model.output\n",
    "    predictions = Dense(14, activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using 4 GPUs\n",
      "WARNING:tensorflow:From /src/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /src/keras/backend/tensorflow_backend.py:4074: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "Weights for the model were loaded successfully\n"
     ]
    }
   ],
   "source": [
    "if num_gpu > 1:\n",
    "    print(\"using\", num_gpu, \"GPUs\")\n",
    "    # build model\n",
    "    with tf.device('/cpu:0'):\n",
    "        model_single_gpu = build_model()\n",
    "        model_weights_dir_name = os.path.join(data_base_output_dir, 'pretrained_models')\n",
    "        model_weights_file_name = 'chexnet_14_weights_712split_epoch_029_val_loss_147.7599.hdf5.bak'\n",
    "        weights_path = os.path.join(model_weights_dir_name, model_weights_file_name)\n",
    "        model_single_gpu.load_weights(weights_path)\n",
    "\n",
    "    # convert to multi-gpu model\n",
    "    model_multi_gpu = multi_gpu_model(model_single_gpu, gpus=num_gpu)\n",
    "    model_checkpoint = MultiGPUCheckpointCallback(\n",
    "        os.path.join(weights_dir, 'azure_chest_xray_14_weights_712split_epoch_{epoch:03d}_val_loss_{val_loss:.4f}.hdf5'),\n",
    "        model_single_gpu, monitor='val_loss', save_weights_only=True)\n",
    "\n",
    "    \n",
    "\n",
    "else:\n",
    "    print(\"using single GPU\")\n",
    "    model_multi_gpu = build_model()\n",
    "    model_checkpoint = ModelCheckpoint(\n",
    "        os.path.join(weights_dir, 'azure_chest_xray_14_weights_712split_epoch_{epoch:03d}_val_loss_{val_loss:.4f}.hdf5'),\n",
    "        monitor='val_loss', save_weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for DataGenSequence train total rows are: 68508 , len is 356\n",
      "for DataGenSequence validation total rows are: 9495 , len is 49\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /src/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/50\n",
      "356/356 [==============================] - 615s 2s/step - loss: 362.5990 - val_loss: 305.8943\n",
      "Epoch 2/50\n",
      "356/356 [==============================] - 531s 1s/step - loss: 358.1175 - val_loss: 299.3387\n",
      "Epoch 3/50\n",
      "356/356 [==============================] - 531s 1s/step - loss: 355.8154 - val_loss: 291.8968\n",
      "Epoch 4/50\n",
      "356/356 [==============================] - 531s 1s/step - loss: 354.0245 - val_loss: 307.2789\n",
      "Epoch 5/50\n",
      "356/356 [==============================] - 531s 1s/step - loss: 352.8441 - val_loss: 296.2510\n",
      "Epoch 6/50\n",
      "356/356 [==============================] - 531s 1s/step - loss: 351.3921 - val_loss: 307.1715\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 7/50\n",
      "356/356 [==============================] - 532s 1s/step - loss: 343.1464 - val_loss: 294.4457\n",
      "Epoch 8/50\n",
      "356/356 [==============================] - 532s 1s/step - loss: 341.2993 - val_loss: 291.3853\n",
      "Epoch 9/50\n",
      "356/356 [==============================] - 531s 1s/step - loss: 340.8073 - val_loss: 293.0704\n",
      "Epoch 10/50\n",
      "356/356 [==============================] - 530s 1s/step - loss: 339.4801 - val_loss: 293.6782\n",
      "Epoch 11/50\n",
      "356/356 [==============================] - 531s 1s/step - loss: 339.2155 - val_loss: 292.1459\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 12/50\n",
      "356/356 [==============================] - 530s 1s/step - loss: 337.7322 - val_loss: 293.7285\n",
      "Epoch 13/50\n",
      "356/356 [==============================] - 529s 1s/step - loss: 337.6498 - val_loss: 293.7916\n",
      "Epoch 14/50\n",
      "356/356 [==============================] - 529s 1s/step - loss: 337.3424 - val_loss: 293.1974\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 15/50\n",
      "356/356 [==============================] - 530s 1s/step - loss: 337.2428 - val_loss: 293.1204\n",
      "Epoch 16/50\n",
      "356/356 [==============================] - 529s 1s/step - loss: 337.4296 - val_loss: 293.3854\n",
      "Epoch 17/50\n",
      "356/356 [==============================] - 529s 1s/step - loss: 337.4242 - val_loss: 293.3500\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 18/50\n",
      "356/356 [==============================] - 529s 1s/step - loss: 337.8277 - val_loss: 293.2384\n",
      "Epoch 19/50\n",
      "356/356 [==============================] - 528s 1s/step - loss: 337.2003 - val_loss: 293.2855\n",
      "Epoch 20/50\n",
      "356/356 [==============================] - 529s 1s/step - loss: 336.6789 - val_loss: 293.5490\n",
      "Epoch 21/50\n",
      "356/356 [==============================] - 529s 1s/step - loss: 337.1009 - val_loss: 293.2094\n",
      "Epoch 22/50\n",
      "356/356 [==============================] - 528s 1s/step - loss: 337.7536 - val_loss: 293.2559\n",
      "Epoch 23/50\n",
      "356/356 [==============================] - 529s 1s/step - loss: 336.9736 - val_loss: 292.8892\n",
      "Epoch 24/50\n",
      "356/356 [==============================] - 529s 1s/step - loss: 337.5975 - val_loss: 293.0444\n",
      "Epoch 25/50\n",
      "356/356 [==============================] - 529s 1s/step - loss: 337.1372 - val_loss: 293.1977\n",
      "Epoch 26/50\n",
      "356/356 [==============================] - 530s 1s/step - loss: 337.3127 - val_loss: 293.0388\n",
      "Epoch 27/50\n",
      "356/356 [==============================] - 529s 1s/step - loss: 337.2290 - val_loss: 293.0619\n",
      "Epoch 28/50\n",
      "356/356 [==============================] - 528s 1s/step - loss: 337.2904 - val_loss: 293.3537\n",
      "Epoch 29/50\n",
      "356/356 [==============================] - 527s 1s/step - loss: 337.3874 - val_loss: 293.1479\n",
      "Epoch 30/50\n",
      "356/356 [==============================] - 529s 1s/step - loss: 337.1126 - val_loss: 293.0979\n",
      "Epoch 31/50\n",
      "356/356 [==============================] - 528s 1s/step - loss: 337.1529 - val_loss: 293.1912\n",
      "Epoch 32/50\n",
      "356/356 [==============================] - 529s 1s/step - loss: 337.2098 - val_loss: 293.1292\n",
      "Epoch 33/50\n",
      "356/356 [==============================] - 529s 1s/step - loss: 337.0810 - val_loss: 292.8809\n",
      "Epoch 34/50\n",
      "356/356 [==============================] - 528s 1s/step - loss: 337.0098 - val_loss: 293.4226\n",
      "Epoch 35/50\n",
      "356/356 [==============================] - 529s 1s/step - loss: 337.0506 - val_loss: 292.7751\n",
      "Epoch 36/50\n",
      "356/356 [==============================] - 529s 1s/step - loss: 337.1078 - val_loss: 292.9827\n",
      "Epoch 37/50\n",
      "356/356 [==============================] - 530s 1s/step - loss: 337.2840 - val_loss: 293.2928\n",
      "Epoch 38/50\n",
      "356/356 [==============================] - 529s 1s/step - loss: 336.9779 - val_loss: 293.0397\n",
      "Epoch 39/50\n",
      "356/356 [==============================] - 528s 1s/step - loss: 337.1013 - val_loss: 293.1292\n",
      "Epoch 40/50\n",
      "356/356 [==============================] - 529s 1s/step - loss: 337.0918 - val_loss: 293.4257\n",
      "Epoch 41/50\n",
      "356/356 [==============================] - 523s 1s/step - loss: 336.9482 - val_loss: 292.9233\n",
      "Epoch 42/50\n",
      "356/356 [==============================] - 522s 1s/step - loss: 337.2137 - val_loss: 293.1470\n",
      "Epoch 43/50\n",
      "356/356 [==============================] - 529s 1s/step - loss: 337.2033 - val_loss: 293.2717\n",
      "Epoch 44/50\n",
      "356/356 [==============================] - 529s 1s/step - loss: 337.3438 - val_loss: 293.1444\n",
      "Epoch 45/50\n",
      "356/356 [==============================] - 528s 1s/step - loss: 337.0391 - val_loss: 293.0329\n",
      "Epoch 46/50\n",
      "356/356 [==============================] - 529s 1s/step - loss: 337.2278 - val_loss: 293.1910\n",
      "Epoch 47/50\n",
      "356/356 [==============================] - 528s 1s/step - loss: 337.2395 - val_loss: 292.8142\n",
      "Epoch 48/50\n",
      "356/356 [==============================] - 529s 1s/step - loss: 336.9253 - val_loss: 292.9922\n",
      "Epoch 49/50\n",
      "356/356 [==============================] - 528s 1s/step - loss: 337.2335 - val_loss: 292.8564\n",
      "Epoch 50/50\n",
      "356/356 [==============================] - 528s 1s/step - loss: 336.6350 - val_loss: 293.1254\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f03ba3cce80>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_workers = num_gpu*2 #*10\n",
    "\n",
    "model_multi_gpu.compile(optimizer=Adam(lr=initial_lr), loss=unweighted_binary_crossentropy)\n",
    "\n",
    "reduce_lr_on_plateau = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1, min_lr=1e-6)\n",
    "\n",
    "callbacks = [model_checkpoint, reduce_lr_on_plateau]\n",
    "\n",
    "with open(label_path, 'rb') as f:\n",
    "    labels = pickle.load(f)\n",
    "\n",
    "with open(partition_path, 'rb') as f:\n",
    "    partition = pickle.load(f)\n",
    "\n",
    "model_multi_gpu.fit_generator(generator=DataGenSequence(labels, partition['train'], current_state='train'),\n",
    "                              epochs=epochs,\n",
    "                              verbose=1,\n",
    "                              callbacks=callbacks,\n",
    "                              workers=num_workers,\n",
    "                              # max_queue_size=32,\n",
    "                              # shuffle=False,\n",
    "                              validation_data=DataGenSequence(labels, partition['valid'], current_state='validation')\n",
    "                              # validation_steps=1\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook 010_train.ipynb to html\n",
      "[NbConvertApp] Writing 349676 bytes to 010_train.html\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to html 010_train.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
