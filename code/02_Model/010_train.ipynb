{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "##### Copyright (C) Microsoft Corporation.  \n",
    "see license file for details "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow multiple displays per cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/local_dir/code/02_Model/../../../..'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AZUREML_NATIVE_SHARE_DIRECTORY mapping to host dir is set by _nativeSharedDirectory_ in .compute file \n",
    "\n",
    "import os\n",
    "baseDataDir =  os.path.join(os.getcwd(), os.path.join(*(['..', '..', '..', '..'])))\n",
    "baseDataDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import utlity functions\n",
    "\n",
    "import sys, os\n",
    "paths_to_append = [os.path.join(os.getcwd(), os.path.join(*([ '..', 'src'])))]\n",
    "def add_path_to_sys_path(path_to_append):\n",
    "    if not (any(path_to_append in paths for paths in sys.path)):\n",
    "        sys.path.append(path_to_append)\n",
    "[add_path_to_sys_path(crt_path) for crt_path in paths_to_append]\n",
    "\n",
    "import azure_chestxray_utils\n",
    "# import azure_chestxray_keras_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the file path variables \n",
    "# paths are tipically container level dirs mapped to a host dir for data persistence.\n",
    "\n",
    "prj_consts = azure_chestxray_utils.chestxray_consts()\n",
    "\n",
    " \n",
    "data_base_input_dir=os.path.join(baseDataDir, os.path.join(*(prj_consts.BASE_INPUT_DIR_list)))\n",
    "data_base_output_dir=os.path.join(baseDataDir, os.path.join(*(prj_consts.BASE_OUTPUT_DIR_list))) \n",
    "\n",
    "# data used for training\n",
    "nih_chest_xray_data_dir=os.path.join(data_base_input_dir, \n",
    "                                     os.path.join(*(prj_consts.ChestXray_IMAGES_DIR_list+['images'])))\n",
    "\n",
    "data_partitions_dir=os.path.join(data_base_output_dir, os.path.join(*(prj_consts.DATA_PARTITIONS_DIR_list))) \n",
    "\n",
    "partition_path = os.path.join(data_partitions_dir, 'partition14_unormalized_cleaned.pickle')\n",
    "label_path = os.path.join(data_partitions_dir,'labels14_unormalized_cleaned.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/local_dir/code/02_Model/../../../../data_dir/chestxray/output/weights_tmpdir'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\r\n"
     ]
    }
   ],
   "source": [
    "# global variables\n",
    "\n",
    "weights_dir = os.path.join(data_base_output_dir, os.path.join(*(prj_consts.MODEL_WEIGHTS_DIR_list))) \n",
    "!mkdir -p {weights_dir}\n",
    "weights_dir\n",
    "!ls -l {weights_dir}\n",
    "\n",
    "# weights_path = os.path.join(\n",
    "#     weights_dir, \n",
    "#     prj_consts.PRETRAINED_DENSENET201_IMAGENET_CHESTXRAY_MODEL_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  # see issue #152\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "ia.seed(1)\n",
    "\n",
    "import cv2\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, Callback, ModelCheckpoint\n",
    "import numpy as np\n",
    "import pickle\n",
    "from keras_contrib.applications.densenet import DenseNetImageNet121\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model\n",
    "from keras.utils import multi_gpu_model\n",
    "from tensorflow.python.client import device_lib\n",
    "import warnings\n",
    "from keras.utils import Sequence\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For testing purpose, we just run 1 epoch. It will take around 25 mins to run for one epoch using 2 K80 GPUs and it is usually needed to run around 30~50 epochs for the model to get converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make force_restart = False if you continue a previous train session, make it True to start from scratch\n",
    "force_restart = False\n",
    "\n",
    "initial_lr = 0.001\n",
    "resized_height = 224\n",
    "resized_width = 224\n",
    "# resized_height = prj_consts.CHESTXRAY_MODEL_EXPECTED_IMAGE_HEIGHT\n",
    "# resized_width = prj_consts.CHESTXRAY_MODEL_EXPECTED_IMAGE_WIDTH\n",
    "num_channel = 3\n",
    "num_classes = 14\n",
    "epochs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu_fraction = 0.4\n",
    "# gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=gpu_fraction)\n",
    "# sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_available_gpus():\n",
    "    \"\"\"\n",
    "\n",
    "    Returns: number of GPUs available in the system\n",
    "\n",
    "    \"\"\"\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "\n",
    "# # get number of available GPUs\n",
    "num_gpu = len(get_available_gpus())\n",
    "num_gpu\n",
    "# num_gpu=2\n",
    "\n",
    "# keras multi_gpu_model slices the data to different GPUs. see https://keras.io/utils/#multi_gpu_model for more details.\n",
    "\n",
    "#48 # 64 seems to be too much on NC12 \n",
    "#96 is too much on 2 x Tesla P100-PCIE-16GB \n",
    "batch_size =num_gpu * 48  \n",
    "\n",
    "\n",
    "# use Keras multi-gpu model, so we need to make sure the batch_size is divisible by num_gpu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device_lib.list_local_devices()\n",
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Keras multi-gpu model, so we need to make sure the batch_size is divisible by num_gpu.\n",
    "\n",
    "# multi GPU model checkpoint. copied from https://github.com/keras-team/keras/issues/8463\n",
    "class MultiGPUCheckpointCallback(Callback):\n",
    "\n",
    "    def __init__(self, filepath, base_model, monitor='val_loss', verbose=0,\n",
    "                 save_best_only=False, save_weights_only=False,\n",
    "                 mode='auto', period=1):\n",
    "        super(MultiGPUCheckpointCallback, self).__init__()\n",
    "        self.base_model = base_model\n",
    "        self.monitor = monitor\n",
    "        self.verbose = verbose\n",
    "        self.filepath = filepath\n",
    "        self.save_best_only = save_best_only\n",
    "        self.save_weights_only = save_weights_only\n",
    "        self.period = period\n",
    "        self.epochs_since_last_save = 0\n",
    "\n",
    "        if mode not in ['auto', 'min', 'max']:\n",
    "            warnings.warn('ModelCheckpoint mode %s is unknown, '\n",
    "                          'fallback to auto mode.' % (mode),\n",
    "                          RuntimeWarning)\n",
    "            mode = 'auto'\n",
    "\n",
    "        if mode == 'min':\n",
    "            self.monitor_op = np.less\n",
    "            self.best = np.Inf\n",
    "        elif mode == 'max':\n",
    "            self.monitor_op = np.greater\n",
    "            self.best = -np.Inf\n",
    "        else:\n",
    "            if 'acc' in self.monitor or self.monitor.startswith('fmeasure'):\n",
    "                self.monitor_op = np.greater\n",
    "                self.best = -np.Inf\n",
    "            else:\n",
    "                self.monitor_op = np.less\n",
    "                self.best = np.Inf\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        self.epochs_since_last_save += 1\n",
    "        if self.epochs_since_last_save >= self.period:\n",
    "            self.epochs_since_last_save = 0\n",
    "            filepath = self.filepath.format(epoch=epoch + 1, **logs)\n",
    "            if self.save_best_only:\n",
    "                current = logs.get(self.monitor)\n",
    "                if current is None:\n",
    "                    warnings.warn('Can save best model only with %s available, '\n",
    "                                  'skipping.' % (self.monitor), RuntimeWarning)\n",
    "                else:\n",
    "                    if self.monitor_op(current, self.best):\n",
    "                        if self.verbose > 0:\n",
    "                            print('Epoch %05d: %s improved from %0.5f to %0.5f,'\n",
    "                                  ' saving model to %s'\n",
    "                                  % (epoch + 1, self.monitor, self.best,\n",
    "                                     current, filepath))\n",
    "                        self.best = current\n",
    "                        if self.save_weights_only:\n",
    "                            self.base_model.save_weights(filepath, overwrite=True)\n",
    "                        else:\n",
    "                            self.base_model.save(filepath, overwrite=True)\n",
    "                    else:\n",
    "                        if self.verbose > 0:\n",
    "                            print('Epoch %05d: %s did not improve' %\n",
    "                                  (epoch + 1, self.monitor))\n",
    "            else:\n",
    "                if self.verbose > 0:\n",
    "                    print('Epoch %05d: saving model to %s' % (epoch + 1, filepath))\n",
    "                if self.save_weights_only:\n",
    "                    self.base_model.save_weights(filepath, overwrite=True)\n",
    "                else:\n",
    "                    self.base_model.save(filepath, overwrite=True)\n",
    "\n",
    "\n",
    "seq = iaa.Sequential([\n",
    "    iaa.Fliplr(0.5),  # horizontal flips\n",
    "    iaa.Affine(rotate=(-15, 15)),  # random rotate image\n",
    "    iaa.Affine(scale=(0.8, 1.1)),  # randomly scale the image\n",
    "], random_order=True)  # apply augmenters in random order\n",
    "\n",
    "\n",
    "# generator for train and validation data\n",
    "# use the Sequence class per issue https://github.com/keras-team/keras/issues/1638\n",
    "class DataGenSequence(Sequence):\n",
    "    def __init__(self, labels, image_file_index, current_state):\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.img_file_index = image_file_index\n",
    "        self.current_state = current_state\n",
    "        self.len = len(self.img_file_index) // self.batch_size\n",
    "        print(\"for DataGenSequence\", current_state, \"total rows are:\", len(self.img_file_index), \", len is\", self.len)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # print(\"loading data segmentation\", idx)\n",
    "        # make sure each batch size has the same amount of data\n",
    "        current_batch = self.img_file_index[idx * self.batch_size: (idx + 1) * self.batch_size]\n",
    "        X = np.empty((self.batch_size, resized_height, resized_width, num_channel))\n",
    "        y = np.empty((self.batch_size, num_classes))\n",
    "\n",
    "        for i, image_name in enumerate(current_batch):\n",
    "            path = os.path.join(nih_chest_xray_data_dir, image_name)\n",
    "            # loading data\n",
    "\n",
    "            img = cv2.resize(cv2.imread(path), (resized_height, resized_width)).astype(np.float32)\n",
    "            X[i, :, :, :] = img\n",
    "            y[i, :] = labels[image_name]\n",
    "\n",
    "            # only do random flipping in training status\n",
    "        if self.current_state == 'train':\n",
    "            x_augmented = seq.augment_images(X)\n",
    "        else:\n",
    "            x_augmented = X\n",
    "\n",
    "        return x_augmented, y\n",
    "\n",
    "\n",
    "# loss function\n",
    "def unweighted_binary_crossentropy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        y_true: true labels\n",
    "        y_pred: predicted labels\n",
    "\n",
    "    Returns: the sum of binary cross entropy loss across all the classes\n",
    "\n",
    "    \"\"\"\n",
    "    return K.sum(K.binary_crossentropy(y_true, y_pred))\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    \"\"\"\n",
    "\n",
    "    Returns: a model with specified weights\n",
    "\n",
    "    \"\"\"\n",
    "    # define the model, use pre-trained weights for image_net\n",
    "    base_model = DenseNetImageNet121(input_shape=(224, 224, 3),\n",
    "                                     weights='imagenet',\n",
    "                                     include_top=False,\n",
    "                                     pooling='avg')\n",
    "\n",
    "    x = base_model.output\n",
    "    predictions = Dense(14, activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using 2 GPUs\n",
      "WARNING:tensorflow:From /src/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /src/keras/backend/tensorflow_backend.py:4074: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "Weights for the model were loaded successfully\n"
     ]
    }
   ],
   "source": [
    "if num_gpu > 1:\n",
    "    print(\"using\", num_gpu, \"GPUs\")\n",
    "    # build model\n",
    "    with tf.device('/cpu:0'):\n",
    "        model_single_gpu = build_model()\n",
    "    # model_single_gpu.load_weights(weights_path)\n",
    "\n",
    "    # convert to multi-gpu model\n",
    "    model_multi_gpu = multi_gpu_model(model_single_gpu, gpus=num_gpu)\n",
    "    model_checkpoint = MultiGPUCheckpointCallback(\n",
    "        os.path.join(weights_dir, 'azure_chest_xray_14_weights_712split_epoch_{epoch:03d}_val_loss_{val_loss:.4f}.hdf5'),\n",
    "        model_single_gpu, monitor='val_loss', save_weights_only=True)\n",
    "\n",
    "    \n",
    "\n",
    "else:\n",
    "    print(\"using single GPU\")\n",
    "    model_multi_gpu = build_model()\n",
    "    model_checkpoint = ModelCheckpoint(\n",
    "        os.path.join(weights_dir, 'azure_chest_xray_14_weights_712split_epoch_{epoch:03d}_val_loss_{val_loss:.4f}.hdf5'),\n",
    "        monitor='val_loss', save_weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for DataGenSequence train total rows are: 68508 , len is 713\n",
      "for DataGenSequence validation total rows are: 9495 , len is 98\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /src/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/4\n",
      "116/713 [===>..........................] - ETA: 17:08 - loss: 237.3335"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-a909811f231f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m                               \u001b[0;31m# max_queue_size=32,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                               \u001b[0;31m# shuffle=False,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDataGenSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartition\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'validation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m                               \u001b[0;31m# validation_steps=1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                               )\n",
      "\u001b[0;32m/src/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/src/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/src/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/src/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_workers = num_gpu*2 #*10\n",
    "\n",
    "model_multi_gpu.compile(optimizer=Adam(lr=initial_lr), loss=unweighted_binary_crossentropy)\n",
    "\n",
    "reduce_lr_on_plateau = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1, min_lr=1e-6)\n",
    "\n",
    "callbacks = [model_checkpoint, reduce_lr_on_plateau]\n",
    "\n",
    "with open(label_path, 'rb') as f:\n",
    "    labels = pickle.load(f)\n",
    "\n",
    "with open(partition_path, 'rb') as f:\n",
    "    partition = pickle.load(f)\n",
    "\n",
    "model_multi_gpu.fit_generator(generator=DataGenSequence(labels, partition['train'], current_state='train'),\n",
    "                              epochs=epochs,\n",
    "                              verbose=1,\n",
    "                              callbacks=callbacks,\n",
    "                              workers=num_workers,\n",
    "                              # max_queue_size=32,\n",
    "                              # shuffle=False,\n",
    "                              validation_data=DataGenSequence(labels, partition['valid'], current_state='validation')\n",
    "                              # validation_steps=1\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to html 010_train.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
